{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.genfromtxt('ex1data2', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardization(x):\n",
    "    mean_residual = []\n",
    "    std_residual  = []\n",
    "    standardization = x\n",
    "    \n",
    "    dimension = x.shape[1]    \n",
    "    for i in range(dimension):\n",
    "        mean = np.mean(x[:, i])\n",
    "        std  = np.std(x[:, i])\n",
    "        \n",
    "        mean_residual.append(mean)\n",
    "        std_residual.append(std)\n",
    "        \n",
    "        standardization[:, i] = (1./std)*(standardization[:, i] - mean)\n",
    "        \n",
    "    return standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_function(x, y, theta):\n",
    "    m = y.size\n",
    "    regression = x.dot(theta)\n",
    "    regressionError = np.sum((regression - y)**2)\n",
    "    return ((1./(2*m))*regressionError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "data = standardization(data)\n",
    "\n",
    "x = data[:, :2]\n",
    "y = data[:, [2]]\n",
    "y = y[:,0]\n",
    "\n",
    "x = np.insert(x, 0, np.ones(x.shape[0]), axis=1)\n",
    "\n",
    "theta = np.array([0., 0., 0.])\n",
    "\n",
    "print(cost_function(x,y,theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, alpha, tolerance):\n",
    "    m = y.size\n",
    "    episilon = 0.000000001\n",
    "    residual = np.ones(tolerance)\n",
    "    interact = 0\n",
    "    converge = False\n",
    "    while not converge:\n",
    "        ' Start adjusting theta values '\n",
    "        hypothesis   = x.dot(theta)\n",
    "        error        = hypothesis - y\n",
    "        gradient     = (1./m)*(x.T.dot(error))\n",
    "        \n",
    "        theta = theta - (alpha)*(gradient)\n",
    "        \n",
    "        ' Run the cost function over the data with new theta '\n",
    "        residual[interact] = cost_function(x, y, theta)\n",
    "        \n",
    "        if interact % 100 == 0:\n",
    "            ' The main idea here is to minimize the error value when evaluating the hypothesis '\n",
    "            print('Error ' + str(residual[interact]))\n",
    "        \n",
    "        ' Verify convergence over the given episilon and residual given step, also verify tolerance tries '\n",
    "        if interact > 0:\n",
    "            converge = (abs(residual[interact] - residual[interact - 1])<episilon)\n",
    "        \n",
    "        if (interact + 1) == tolerance:\n",
    "            converge = True\n",
    "            \n",
    "        interact = interact + 1\n",
    "        \n",
    "    return theta, residual, interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 0.490801517053\n",
      "Error 0.184498002757\n",
      "Error 0.15045061142\n",
      "Error 0.140352893834\n",
      "Error 0.136345120418\n",
      "Error 0.134693517549\n",
      "Error 0.134010154497\n",
      "Error 0.133727289427\n",
      "Error 0.133610197731\n",
      "Error 0.133561727527\n",
      "Error 0.133541663238\n",
      "Error 0.133533357604\n",
      "Error 0.133529919478\n",
      "Error 0.133528496263\n",
      "Error 0.133527907121\n",
      "Last interaction was 1500\n",
      "[ -7.63219275e-17   8.84137547e-01  -5.25503786e-02]\n"
     ]
    }
   ],
   "source": [
    "(t,r,i) = gradient_descent(x, y, theta, 0.01, 1500)\n",
    "\n",
    "print('Last interaction was '+str(i))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
